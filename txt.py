import os
import asyncio
from datetime import datetime
from collections import defaultdict
import logging

from pyrogram import Client
from pyrogram.errors import FloodWait

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Google Colab ---
# ÙŠÙØ¶Ù„ Ø¥Ø¨Ù‚Ø§Ø¡ Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© ÙƒÙ…Ø§ Ù‡ÙŠ ÙÙŠ Colab

# Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© (Ø§Ø®ØªØ± ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· ÙˆØ¹Ù„Ù‘Ù‚ Ø§Ù„Ø£Ø®Ø±Ù‰)
# 1. Ù„Ù„Ù…ØµØ§Ø¯Ù‚Ø© ÙƒÙ…Ø³ØªØ®Ø¯Ù… (Ù…ÙˆØµÙ‰ Ø¨Ù‡)
os.environ['API_ID'] = '27361100'
os.environ['API_HASH'] = '70f07944c80e1e52784f14cfe49f37fa'
os.environ['SESSION'] = 'BAGhf0wArwf6IT8U920coX5ZRamBo0_siOuRfy3r26gmxlZN-ysalq6araUZ5B9-h4XhkW3B1XRu6TrKx0zOEdGtp4orE5c0u9da4Rny-GHoRmUFOZ3imdsjzNW0KucaEwhoUYORSs7ZYDPLOS4C5bZlXFbaI8FAjUnkVS8P4nQdIFp6BUinShexzjgXPR4oRzRZb5kHhvdIvzfK9aDmYfqcUErOqcA0D_5cp-9lx6p2eA6OkdUA6Yed8TjcKEzfxHqri3g_XH0KwSjq4cePPaqLFK_6sVuPPmikbj9Fs6LwoBINaYyz41e_r6ABYwByXisDPthsE4hXSJCKnHPYANqe_gY_agAAAAHlNiU8AA'

# 2. Ù„Ù„Ù…ØµØ§Ø¯Ù‚Ø© ÙƒØ¨ÙˆØª (Ø¥Ø°Ø§ ÙƒÙ†Øª ØªÙØ¶Ù„ Ø°Ù„Ùƒ)
# ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¨ÙˆØª Ù…Ø´Ø±Ù ÙÙŠ Ø§Ù„Ù‚Ù†Ø§Ø©
# os.environ['BOT_TOKEN'] = '8186829116:AAEAVKLdmg-BuZ5D4mhE4Ch1nLOWd0-LK3I'

# Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚Ù†Ø§Ø© ÙˆØ§Ù„Ø¨Ø­Ø«
os.environ['CHANNEL_ID'] = "-1002603961050"
os.environ['CHANNEL_ID_LOG'] = "-1002603961050" # ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø±Ù‚Ù…Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ Ø£Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø®Ø±Ù‰
os.environ['FIRST_MSG_ID'] = '1'
os.environ['LAST_MSG_ID'] = '1000' # ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø¯Ø¹Ù… Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…ØªØºÙŠØ±


# --- Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Ù„Ø§ ØªØ¹Ø¯Ù„ Ù…Ø§ Ø¨Ø¹Ø¯ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø·) ---

# Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
API_ID = os.getenv("API_ID")
API_HASH = os.getenv("API_HASH")
BOT_TOKEN = os.getenv("BOT_TOKEN")
SESSION_STRING = os.getenv("SESSION")

try:
    CHANNEL_ID = int(os.getenv("CHANNEL_ID"))
    CHANNEL_ID_LOG = int(os.getenv("CHANNEL_ID_LOG"))
    FIRST_MSG_ID = int(os.getenv("FIRST_MSG_ID"))
    LAST_MSG_ID = int(os.getenv("LAST_MSG_ID", "0")) # Ø§Ø¬Ø¹Ù„Ù‡ 0 Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
except (TypeError, ValueError) as e:
    logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©: {e}. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­ØªÙ‡Ø§.")
    exit()

# Ø§Ø®ØªÙŠØ§Ø± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©
if SESSION_STRING:
    logger.info("ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ SESSION. Ø³ÙŠØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙƒÙ€ (Ù…Ø³ØªØ®Ø¯Ù…).")
    app = Client("user_session", session_string=SESSION_STRING, api_id=API_ID, api_hash=API_HASH)
elif BOT_TOKEN:
    logger.info("ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ BOT_TOKEN. Ø³ÙŠØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙƒÙ€ (Ø¨ÙˆØª).")
    app = Client("bot_session", api_id=API_ID, api_hash=API_HASH, bot_token=BOT_TOKEN)
else:
    logger.error("Ø®Ø·Ø£ ÙØ§Ø¯Ø­: ÙŠØ¬Ø¨ ØªÙˆÙÙŠØ± SESSION Ø£Ùˆ BOT_TOKEN Ù„Ù„Ù…ØµØ§Ø¯Ù‚Ø©.")
    exit()


async def find_duplicates():
    files_by_size = defaultdict(list)
    messages_scanned = 0
    files_found = 0
    start_time = datetime.now()

    try:
        await app.send_message(CHANNEL_ID_LOG, "â³ Ø¬Ø§Ø±Ù Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©...")

        # ØªØ­Ø¯ÙŠØ¯ Ù†Ø·Ø§Ù‚ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
        message_ids = range(FIRST_MSG_ID, LAST_MSG_ID + 1)
        total_messages_to_scan = len(message_ids)
        logger.info(f"Ø³ÙŠØªÙ… ÙØ­Øµ {total_messages_to_scan} Ø±Ø³Ø§Ù„Ø© Ù…Ù† ID {FIRST_MSG_ID} Ø¥Ù„Ù‰ {LAST_MSG_ID}.")

        # Ø¬Ù„Ø¨ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙÙŠ Ø¯ÙØ¹Ø§Øª (Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø©)
        for i in range(0, total_messages_to_scan, 200): # Ø¯ÙØ¹Ø© Ù…Ù† 200 Ø±Ø³Ø§Ù„Ø©
            chunk_ids = message_ids[i:i + 200]
            try:
                messages = await app.get_messages(chat_id=CHANNEL_ID, message_ids=chunk_ids)

                for message in messages:
                    if not message: # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ø­Ø°ÙˆÙØ© Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©
                        continue
                        
                    messages_scanned += 1
                    
                    file_info = None
                    if message.document: file_info = message.document
                    elif message.video: file_info = message.video
                    elif message.audio: file_info = message.audio
                    elif message.photo: file_info = message.photo

                    if file_info and hasattr(file_info, 'file_size'):
                        files_found += 1
                        files_by_size[file_info.file_size].append((message.id, message.link))
                
                logger.info(f"Ø§Ù„ØªÙ‚Ø¯Ù…: ØªÙ… ÙØ­Øµ {messages_scanned}/{total_messages_to_scan} Ø±Ø³Ø§Ù„Ø©...")

            except FloodWait as e:
                logger.warning(f"ØªÙ… ØªÙ‚ÙŠÙŠØ¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª. Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„Ù…Ø¯Ø© {e.value} Ø«Ø§Ù†ÙŠØ©...")
                await asyncio.sleep(e.value + 2) # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± + Ø«Ø§Ù†ÙŠØªÙŠÙ† Ø¥Ø¶Ø§ÙÙŠØªÙŠÙ†
            except Exception as e:
                logger.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„: {e}")
                continue # Ø§Ø³ØªÙ…Ø± Ù…Ø¹ Ø§Ù„Ø¯ÙØ¹Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©

    except Exception as e:
        error_message = f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ÙØ­Øµ: {e}"
        logger.error(error_message, exc_info=True) # Ø·Ø¨Ø§Ø¹Ø© ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        await app.send_message(CHANNEL_ID_LOG, f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙˆØªÙˆÙ‚ÙØª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:\n`{e}`")
        return

    logger.info("Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ÙØ­Øµ. Ø¬Ø§Ø±Ù ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±...")
    
    # --- ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ± (Ù†ÙØ³ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚) ---
    duplicate_groups = {size: messages for size, messages in files_by_size.items() if len(messages) > 1}
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    report_filename = f"report_duplicates_{timestamp}.txt"
    total_duplicate_files = sum(len(messages) - 1 for messages in duplicate_groups.values())
    
    with open(report_filename, "w", encoding="utf-8") as f:
        # ... (Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù„Ù… ÙŠØªØºÙŠØ±ØŒ ÙˆÙ‡Ùˆ ØµØ­ÙŠØ­)
        f.write("ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© ÙÙŠ Ù‚Ù†Ø§Ø© ØªÙ„ÙŠØ¬Ø±Ø§Ù…\n")
        f.write("="*40 + "\n\n")
        f.write("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©:\n")
        f.write("-" * 20 + "\n")
        f.write(f"ØªØ§Ø±ÙŠØ® Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Ù…Ø¯Ø© Ø§Ù„ÙØ­Øµ: {datetime.now() - start_time}\n")
        f.write(f"Ù†Ø·Ø§Ù‚ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù…ÙØ­ÙˆØµØ©: Ù…Ù† {FIRST_MSG_ID} Ø¥Ù„Ù‰ {LAST_MSG_ID}\n")
        f.write(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§: {files_found}\n")
        f.write(f"Ø¹Ø¯Ø¯ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©: {len(duplicate_groups)}\n")
        f.write(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù…ÙƒØ±Ø±Ø©: {total_duplicate_files}\n\n")
        f.write("="*40 + "\n\n")
        
        if not duplicate_groups:
            f.write("ğŸ‰ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù„ÙØ§Øª Ù…ÙƒØ±Ø±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù.\n")
        else:
            f.write("ğŸ” ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©:\n\n")
            sorted_groups = sorted(duplicate_groups.items(), key=lambda item: item[0], reverse=True)
            for i, (size, messages) in enumerate(sorted_groups, 1):
                messages.sort(key=lambda x: x[0])
                original_msg_id, original_link = messages[0]
                duplicate_links = [link for msg_id, link in messages[1:]]
                f.write(f"--- Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø±Ù‚Ù… {i} (Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: {size / 1024 / 1024:.2f} MB) ---\n")
                f.write(f"Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© (Ø§Ù„Ø£Ù‚Ø¯Ù…): {original_link}\n")
                f.write(f"Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù…ÙƒØ±Ø±Ø© ({len(duplicate_links)}):\n")
                for dup_link in duplicate_links:
                    f.write(f"  - {dup_link}\n")
                f.write("\n")

    logger.info(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„Ù…Ù„Ù: {report_filename}")

    completion_message = (
        f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙØ­Øµ Ø¨Ù†Ø¬Ø§Ø­!\n\n"
        f"ğŸ“„ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù…Ø­Ù„ÙŠØ§Ù‹ Ø¨Ø§Ø³Ù…:\n`{report_filename}`\n\n"
        f"** Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:**\n"
        f"- Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù…ÙØ­ÙˆØµØ©: {messages_scanned}\n"
        f"- Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ù…ÙƒØ±Ø±Ø©: {len(duplicate_groups)}\n"
        f"- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª: {total_duplicate_files}"
    )
    await app.send_message(CHANNEL_ID_LOG, completion_message)
    if os.path.getsize(report_filename) < 50 * 1024 * 1024:
        await app.send_document(CHANNEL_ID_LOG, report_filename, caption="ğŸ“„ Ù…Ø±ÙÙ‚ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙØ§ØµÙŠÙ„")


async def main():
    logger.info("Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±Ø¨Øª...")
    try:
        await app.start()
        await find_duplicates()
    except Exception as e:
        logger.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø¹Ù„Ù‰: {e}", exc_info=True)
    finally:
        if app.is_connected:
            await app.stop()
        logger.info("Ø§Ù†ØªÙ‡Ù‰ ØªÙ†ÙÙŠØ° Ø§Ù„Ø³ÙƒØ±Ø¨Øª.")

# ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯
asyncio.run(main())
